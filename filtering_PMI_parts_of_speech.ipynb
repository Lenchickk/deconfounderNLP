{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering n-grams based on type of the speech and PMI\n",
    "\n",
    "We need to get the spreadshit (a csv-file) for 3-grams for each file with textual observations (the congressional speeches, TV transcripts for 3 channels) of the following structure:\n",
    "\n",
    "$<position><n-gram><frequency><relative frequency=(double)(frequency/number of observations)><PMI><tagpattern>$\n",
    "    \n",
    "1) $PMI(n = 3) = P(w_1 w_2 w_3)/ (P(w_1* w_2*w_3) = count(w_1 w_2 w_3)/(count(w_1 w_2 w_3) + count(w_1 w_3 w_2) + count(w_2 w_1 w_3) + count(w_2 w_3 w_1) + count(w_3 w_1 w_2)+count(w_3 w_2 w_1) ) $\n",
    "\n",
    "2) Tagpatterns, see Elliott's code: ln.11. \n",
    "\n",
    "Important! The only preproprosseing you need before constructing this table: 1) remove all punctuation marks 2) Convert the text to the lower case. \n",
    "\n",
    "Eliiott's code:\n",
    "https://github.com/ellliottt/text_ml_course_2018/blob/master/notebooks/nb_05_features-2.ipynb\n",
    "\n",
    "(starting on line 10)\n",
    "\n",
    "General formula for an n-gram: PMI = Prob. of collocation, actual / Prob. of collocation, if independent\n",
    "\n",
    "Below is just some experiments with the basic stuff from spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "text = 'Science cannot solve the ultimate mystery of nature. And that is because, in the last analysis, we ourselves are a part of the mystery that we are trying to solve.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' scienc cannot solv the ultim mysteri of natur and that is because in the last analysi we ourselves are a part of the mysteri that we are tri to solv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "words = tokenizer.tokenize(text.lower())\n",
    "\n",
    "text_stemmed =\"\"\n",
    "for word in words:\n",
    "    text_stemmed = text_stemmed + \" \" + stemmer.stem(word)\n",
    "\n",
    "doc2 = nlp(text_stemmed)\n",
    "\n",
    "text_stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'science cannot solve the ultimate mystery of nature. and that is because, in the last analysis, we ourselves are a part of the mystery that we are trying to solve.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science cannot solve the ultimate mystery of nature.\n",
      "solve\n",
      "[(Science, 'nsubj'), (can, 'aux'), (not, 'neg'), (solve, 'ROOT'), (the, 'det'), (ultimate, 'amod'), (mystery, 'dobj'), (of, 'prep'), (nature, 'pobj'), (., 'punct')]\n",
      "\n",
      "And that is because, in the last analysis, we ourselves are a part of the mystery that we are trying to solve.\n",
      "is\n",
      "[(And, 'cc'), (that, 'nsubj'), (is, 'ROOT'), (because, 'mark'), (,, 'punct'), (in, 'prep'), (the, 'det'), (last, 'amod'), (analysis, 'pobj'), (,, 'punct'), (we, 'nsubj'), (ourselves, 'appos'), (are, 'advcl'), (a, 'det'), (part, 'attr'), (of, 'prep'), (the, 'det'), (mystery, 'pobj'), (that, 'dobj'), (we, 'nsubj'), (are, 'aux'), (trying, 'relcl'), (to, 'aux'), (solve, 'xcomp'), (., 'punct')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print(sent.root)\n",
    "    print([(w, w.dep_) for w in sent])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " scienc cannot solv the ultim mysteri of natur and that is because in the last analysi we ourselves are a part of the mysteri that we are tri to solv\n",
      "solv\n",
      "[( , ''), (scienc, 'nsubj'), (can, 'aux'), (not, 'neg'), (solv, 'ROOT'), (the, 'det'), (ultim, 'amod'), (mysteri, 'dobj'), (of, 'prep'), (natur, 'pobj'), (and, 'cc'), (that, 'nsubj'), (is, 'conj'), (because, 'mark'), (in, 'prep'), (the, 'det'), (last, 'amod'), (analysi, 'pobj'), (we, 'nsubj'), (ourselves, 'appos'), (are, 'advcl'), (a, 'det'), (part, 'attr'), (of, 'prep'), (the, 'det'), (mysteri, 'pobj'), (that, 'mark'), (we, 'nsubj'), (are, 'ccomp'), (tri, 'acomp'), (to, 'aux'), (solv, 'xcomp')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    print(sent)\n",
    "    print(sent.root)\n",
    "    print([(w, w.dep_) for w in sent])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
